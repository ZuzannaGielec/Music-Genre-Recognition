{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1W9murL3IbR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XpbjZD8ZHaW",
        "outputId": "246d6526-6373-4016-dc11-b66c6f59b8ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-57720363cec5>:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(audio_data), np.array(labels)\n"
          ]
        }
      ],
      "source": [
        "# Function to load audio files from a directory\n",
        "def load_audio_files(directory):\n",
        "    audio_data = []\n",
        "    labels = []\n",
        "    for genre in os.listdir(directory):\n",
        "        genre_path = os.path.join(directory, genre)\n",
        "        for filename in os.listdir(genre_path):\n",
        "            filepath = os.path.join(genre_path, filename)\n",
        "            audio, sr = librosa.load(filepath, duration=30, sr=None)\n",
        "            audio_data.append(audio)\n",
        "            labels.append(genre)\n",
        "    return np.array(audio_data), np.array(labels)\n",
        "\n",
        "# Function to split data into training and testing sets\n",
        "def split_train_test_data(X, y, test_size=0.2, random_state=42):\n",
        "    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
        "\n",
        "#Function to create 3-second audio segments from the original 30-second clips\n",
        "def create_3s_audio_segments(audio_data):\n",
        "    audio_segments = []\n",
        "    for audio in audio_data:\n",
        "        for i in range(0, len(audio), 3 * 22050):  # Assuming 22050 samples per second\n",
        "            segment = audio[i:i + 3 * 22050]\n",
        "            if len(segment) == 3 * 22050:\n",
        "                audio_segments.append(segment)\n",
        "    return np.array(audio_segments)\n",
        "\n",
        "# Function to generate mel spectrograms from audio data\n",
        "def create_spectrograms_30s(audio_data, labels, save_path):\n",
        "    for i, (audio, genre) in enumerate(zip(audio_data, labels)):\n",
        "        plt.figure(figsize=(2, 2))\n",
        "        S = librosa.feature.melspectrogram(y=audio, sr=22050)\n",
        "        librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
        "        plt.axis('off')\n",
        "        spectrogram_filename = f'spectrogram_{i}_{genre}.png'\n",
        "        plt.savefig(os.path.join(save_path, spectrogram_filename))\n",
        "        plt.close()\n",
        "\n",
        "# Function to build a CNN model for music genre classification\n",
        "def build_cnn_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Main function for music genre classification\n",
        "def music_genre_classification():\n",
        "    # Load original GTZAN dataset\n",
        "    data_directory = '../Data/genres_original'\n",
        "    audio_data, labels = load_audio_files(data_directory)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = split_train_test_data(audio_data, labels)\n",
        "\n",
        "    # # Create 3-second audio segments\n",
        "    # X_train_3s = create_3s_audio_segments(X_train)\n",
        "    # X_test_3s = create_3s_audio_segments(X_test)\n",
        "\n",
        "    # Create spectrograms and save to folders\n",
        "    spectrogram_save_path_train = '../Data/spectograms_train'\n",
        "    spectrogram_save_path_test = '../Data/spectograms_test'\n",
        "    create_spectrograms_30s(X_train, y_train, spectrogram_save_path_train)\n",
        "    create_spectrograms_30s(X_test, y_test, spectrogram_save_path_test)\n",
        "\n",
        "    # Build CNN model\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2], 1)  # Adjust dimensions based on spectrogram size\n",
        "    num_classes = len(np.unique(labels))\n",
        "    model = build_cnn_model(input_shape, num_classes)\n",
        "\n",
        "    # Preprocess data for CNN\n",
        "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
        "\n",
        "    y_train_categorical = to_categorical(y_train, num_classes=num_classes)\n",
        "    y_test_categorical = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train_categorical, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "    y_true = np.argmax(y_test_categorical, axis=1)\n",
        "\n",
        "    # Print accuracy and confusion matrix\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "# Run the music genre classification\n",
        "music_genre_classification()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCP4Tcsv4lhz"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_data(data_path, target_shape=(128, 2500)):\n",
        "    genres = os.listdir(data_path)\n",
        "    labels = []\n",
        "    mel_specs = []\n",
        "\n",
        "    for genre in genres:\n",
        "        genre_path = os.path.join(data_path, genre)\n",
        "        for filename in os.listdir(genre_path):\n",
        "            file_path = os.path.join(genre_path, filename)\n",
        "            try:\n",
        "                audio, _ = librosa.load(file_path, res_type='kaiser_fast', duration=30)\n",
        "                mel_spec = librosa.feature.melspectrogram(y=audio, sr=22050, n_mels=128)\n",
        "\n",
        "                # Ensure all mel spectrograms have the same shape\n",
        "                mel_spec = librosa.util.fix_length(mel_spec, target_shape[1], axis=1, mode='constant', value=0)\n",
        "\n",
        "                mel_specs.append(mel_spec)\n",
        "                labels.append(genre)\n",
        "            except (librosa.util.exceptions.LibrosaError, FileNotFoundError) as e:\n",
        "                print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "    return np.array(mel_specs), np.array(labels)\n",
        "\n",
        "data_path = \"../Data/genres_original\"\n",
        "mel_specs, labels = load_data(data_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMkD3E9h4qH7"
      },
      "outputs": [],
      "source": [
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(mel_specs, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Build the CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(128, X_train.shape[2], 1)),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(np.unique(labels)), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsSbwYQQ4ta-"
      },
      "outputs": [],
      "source": [
        "# Step 4: Train the model\n",
        "X_train = X_train[..., np.newaxis]  # Add channel dimension\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "X_test = X_test[..., np.newaxis]  # Add channel dimension\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTK1qes84wla"
      },
      "outputs": [],
      "source": [
        "# Step 6: Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(labels), yticklabels=np.unique(labels))\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
